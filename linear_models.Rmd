---
title: "Linear Models"
output: github_document
date: "2022-11-10"
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
set.seed(1)

knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Model fitting

Let's load the airbnb data.

```{r}
data("nyc_airbnb")

nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(stars = review_scores_location / 2) %>% 
  rename(
    borough = neighbourhood_group,
    neighborhood = neighbourhood) %>% 
  filter(borough != "Staten Island") %>% 
  select(price, stars, borough, neighborhood, room_type)
```

An good place to start is to consider price as an outcome that may depend on rating and borough. We fit that initial model in the following code.

```{r}
fit = lm(price ~ stars + borough, data = nyc_airbnb)
```

The `lm` function begins with the formula specification – outcome on the left of the `~` and predictors separated by `+` on the right. As we’ll see shortly, interactions between variables can be specified using `*`. You can also specify an intercept-only model (`outcome ~ 1`), a model with no intercept (`outcome ~ 0 + ...`), and a model using all available predictors (`outcome ~ .`).

R will treat categorical (factor) covariates appropriately and predictably: indicator variables are created for each non-reference category and included in your model, and the factor level is treated as the reference. As with `ggplot`, being careful with factors is therefore critical!

```{r}
nyc_airbnb = 
  nyc_airbnb %>% 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type))

fit = lm(price ~ stars + borough, data = nyc_airbnb)
```

## Tidying output

The output of a `lm` is an object of class `lm` – a very specific list that isn’t a dataframe but that can be manipulated using other functions. Some common functions for interacting with lm fits are below, although we omit the output.

```{r, eval = FALSE}
summary(fit$coefficients) #Not great
summary(fit)
summary(fit)$coef
coef(fit)
fitted.values(fit)
```

We can tidy our model output into a clean dataframe. The `broom` package has functions for obtaining a quick summary of the model and for cleaning up the coefficient table.

```{r}
fit %>% 
  broom::glance()

fit %>% 
  broom::tidy() %>% 
  mutate(
    term = str_replace(term, "borough", "Borough: ")
  ) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 2)
```

Category 1 is the reference category in regression!
Let's change the reference category...R will automatically level categorical factors in alphabetical order, but we want to set the reference level to the most frequent observed category. 

Note how we use pipes in `lm` - it expects a formula first and a dataframe second. If the first argument isn't a dataframe, we have to specify where it goes using `.`

```{r}
fit = nyc_airbnb %>% 
  mutate(
    borough = fct_infreq(borough),
    room_type = fct_infreq(room_type)) %>% 
  lm(price ~ stars + borough, data = .) 

fit %>% 
  broom::tidy() %>% 
  mutate(
    term = str_replace(term, "borough", "Borough: ")
  ) %>% 
  select(term, estimate, p.value) %>% 
  knitr::kable(digits = 2)

```

```{r}
fit %>% 
  broom::glance() %>% 
  select(AIC)
```

As an aside, `broom::tidy` works with lots of things, including most of the functions for model fitting you’re likely to run into (survival, mixed models, additive models, …).

## Diagnostics

We want to get residuals from the model we just fit and plot them.

```{r}
modelr::add_residuals(nyc_airbnb, fit) %>% 
  ggplot(aes(x = stars, y = resid)) + 
  geom_point()
```

These residuals don't look very random...there is way more variance for stars 4-5 versus 1-2. If we want to do hypothesis testing, we may worry about non-constant variance. 

```{r}
nyc_airbnb %>% 
  modelr::add_residuals(fit) %>% 
  ggplot(aes(x = borough, y = resid)) +
  geom_violin() + 
  ylim(-250, 250)
```

Assumptions for constant variance aren't met but the sample size is big. There are a few things we might try to do here – including creating a formal rule for the exclusion of outliers, transforming the price variable (e.g. using a log transformation), or fitting a model that is robust to outliers. 

## Hypothesis testing

One coefficient (let's say `stars`):

```{r}
fit %>% 
  broom::tidy()

fit_null = lm(price ~ stars, data = nyc_airbnb) # Intercept and stars
fit_alt = lm(price ~ stars + borough, data = nyc_airbnb) #Intercept and 2 variables

anova(fit_null, fit_alt) %>% 
  broom::tidy()
```

Note that this works for *nested* models only. Comparing non-nested models is a common problem that requires other methods; we’ll see one approach in cross validation.

# Room type by borough

Interactions...?

```{r}
fit = 
  nyc_airbnb %>% 
  lm(price ~ stars + borough * room_type, data = .)

fit %>% 
  broom::tidy()
```

## Nesting data

So...can we fit models by borough? (fit models within a dataframe for each borough?) YES, with `map`!

```{r}
nest_lm_res =
  nyc_airbnb %>% 
  nest(data = -borough) %>% 
  mutate(
    models = map(data, ~lm(price ~ stars + room_type, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest(results)
```

Quick double check...?

```{r}
nyc_airbnb %>% 
  filter(borough == "Bronx") %>% #Change borough name
  lm(price ~ stars + room_type, data = .) %>% 
  broom::tidy()
```

What if we wanted all these boroughs at the same time?

```{r}
nest_lm_res %>% 
  select(borough, term, estimate) %>% 
  mutate(term = fct_inorder(term)) %>% 
  pivot_wider(
    names_from = term, values_from = estimate) %>% 
  knitr::kable(digits = 3)
```

